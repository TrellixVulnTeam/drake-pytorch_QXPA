{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pydrake\n",
    "from pydrake.all import (\n",
    "    AutoDiffXd, Expression, Variable,\n",
    "    MathematicalProgram, SolverType, SolutionResult,\n",
    "    DirectCollocationConstraint, AddDirectCollocationConstraint,\n",
    "    PiecewisePolynomial,\n",
    "    DiagramBuilder, SignalLogger, Simulator, VectorSystem,\n",
    ")\n",
    "\n",
    "from traj.dircol import (\n",
    "    make_real_dircol_mp,\n",
    ")\n",
    "\n",
    "from nn_system.NNSystemHelper import (\n",
    "    make_NN_constraint,\n",
    ")\n",
    "\n",
    "from nn_system.networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params:  438\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#       SETTINGS\n",
    "##############################\n",
    "# kNetConstructor = FC\n",
    "# kNetConstructor = MLPSMALL\n",
    "kNetConstructor = MLP\n",
    "kNumTimesteps = 21\n",
    "prog, tree = make_real_dircol_mp(expmt=\"acrobot\", seed=1776)\n",
    "\n",
    "# Make vars for mathematical program to know about neural network\n",
    "num_params = sum(tensor.nelement() for tensor in kNetConstructor().parameters())\n",
    "num_inputs = 1\n",
    "num_states = 4\n",
    "print(\"total params: \", sum((num_inputs, num_states, num_params)))\n",
    "T = prog.NewContinuousVariables(num_params, 'T')\n",
    "\n",
    "# Apply this NN constraint to all timesteps!\n",
    "for t in range(kNumTimesteps):\n",
    "    # Only one output value, so let's have lb and ub of just size one!\n",
    "    constraint = make_NN_constraint(kNetConstructor, num_inputs, num_states, num_params)\n",
    "    lb         = -np.array([.1])\n",
    "    ub         = np.array([.1])\n",
    "    var_list   = np.hstack((prog.input(t), prog.state(t), T))\n",
    "    prog.AddConstraint(constraint, lb, ub, var_list)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Run this cell to run the code!\n",
    "############################################################\n",
    "\n",
    "prog.SetSolverOption(SolverType.kSnopt, 'Print file', \"/tmp/snopt.out\")\n",
    "ret = prog.Solve()\n",
    "\n",
    "x_trajectory = prog.ReconstructStateTrajectory()\n",
    "breaks = np.linspace(x_trajectory.start_time(),x_trajectory.end_time(),100)\n",
    "x_knots = np.hstack([x_trajectory.value(t) for t in breaks])\n",
    "\n",
    "plt.plot(breaks, x_knots[0,:], breaks, x_knots[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test make_NN_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params:  134\n"
     ]
    }
   ],
   "source": [
    "# kNetConstructor = FC\n",
    "kNetConstructor = MLPSMALL\n",
    "num_params = sum(tensor.nelement() for tensor in kNetConstructor().parameters())\n",
    "num_inputs = 1\n",
    "num_states = 4\n",
    "total_params = sum((num_inputs, num_states, num_params))\n",
    "print(\"total params: \", total_params)\n",
    "\n",
    "constraint = make_NN_constraint(kNetConstructor, num_inputs, num_states, num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "np.random.seed(1776)\n",
    "# Make total_param number of AutoDiffXd's, with (seeded) random values.\n",
    "# Set derivatives array to length total_param with only index i set for ith AutoDiff.\n",
    "# values = np.random.randn(total_params)\n",
    "values = np.ones(total_params)\n",
    "def one_hot(i, n_params):\n",
    "    ret = np.zeros(n_params)\n",
    "    ret[i] = 1\n",
    "    return ret\n",
    "\n",
    "uxT = np.array([AutoDiffXd(values[i], one_hot(i, total_params)) for i in range(total_params)])\n",
    "out = copy.deepcopy(constraint(uxT)[0])\n",
    "out_value = out.value()\n",
    "out_derivatives = out.derivatives()\n",
    "\n",
    "# f     : function(np.array of AutoDiffXd's) -> array of size one of AutoDiffXd\n",
    "# x     : np.array of AutoDiffXd at which to calculate finite_difference\n",
    "# idx   : Index of AutoDiffXd in x to perturb\n",
    "# delta : magnitude of perturbation of AutoDiffXd at index idx of x\n",
    "def finite_difference(f, x, idx, delta):\n",
    "    x_hi = copy.deepcopy(x)\n",
    "    x_hi[idx] += delta\n",
    "    x_lo = copy.deepcopy(x)\n",
    "    x_lo[idx] -= delta\n",
    "    return ( f(x_hi)[0].value() - f(x_lo)[0].value() ) / (2*delta)\n",
    "\n",
    "for idx in range(total_params):    \n",
    "    # Do finite difference calculation and compare against gradient\n",
    "    grad = finite_difference(constraint, uxT, idx, 0.1)\n",
    "    ref_grad = out_derivatives[idx]\n",
    "    np.testing.assert_allclose(grad, ref_grad, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
